---
title: "MA678 Homework 5"
author: "Su Xu"
date: "10/25/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rstanarm)
library(arm)
library(performance)
library(AER)
library(haven)
library(VGAM)
library(brms)
library(bayesplot)
```

## 15.1 Poisson and negative binomial regression
The folder `RiskyBehavior` contains data from a randomized trial targeting couples at high risk of HIV infection. The intervention provided counseling sessions regarding practices that could reduce their likelihood of contracting HIV. Couples were randomized either to a control group, a group in which just the woman participated, or a group in which both members of the couple participated. One of the outcomes examined after three months was "number of unprotected sex acts."  

```{r}
#read data
risky <- read.csv("../data/ROS-Examples-master/RiskyBehavior/data/risky.csv")
#convert couples and women_alone into factor variables, convert fupacts as numeric without decimal.
risky %>% 
  mutate(couples = factor(couples),
         women_alone = factor(women_alone),
         fupacts = round(fupacts)) -> risky
head(risky)
```


### a) 
Model this outcome as a function of treatment assignment using a Poisson regression. Does the model fit well? Is there evidence of overdispersion?  

The (couples, women_alone) combination as (0,0) is the control group, (0,1) is a group in which just the woman participated, (1,0) is a group in which both members of the couple participated.

```{r}
#model fit
fit151 <- stan_glm(fupacts ~ women_alone + couples,
                   family = poisson(link = "log"),
                   data = risky,
                   refresh = 0)
#model summary table
summary(fit151)
#residual plot and binned residual plot
par(mfrow=c(1,2))
plot(x = fit151$linear.predictors,
     y = fit151$residuals,
     xlab = "Expected value",
     ylab = "residual",
     main = "residual plot")
abline(a = 0,
       b = 0,
       lty = 3)
binnedplot(x = fit151$linear.predictors,
              y = fit151$residuals)
#overdispersion check
check_overdispersion(fit151)
```

The overdispersion test shows that the dispersion ratio is far larger than 1, overdispersion detected.
Even though the p-value for the constant and two variables are smaller than 0.05, which can indicate a statistical significance, but due to the high overdispersion, the model does not fit well.

### b) 
Next extend the model to include pre-treatment measures of the outcome and the additional pre-treatment variables included in the dataset. Does the model fit well? Is there evidence of overdispersion?  

```{r}
#convert variable `bs_hiv` into a factor variable, normalize the variable bupacts
risky %>% 
  mutate(bs_hiv = case_when(risky$bs_hiv == "negative" ~ 0,
                            risky$bs_hiv == "positive" ~ 1)) %>% 
  mutate(bs_hiv = as.factor(bs_hiv)) -> risky
```

```{r}
#fit the model
fit1512 <- stan_glm(fupacts ~ women_alone + couples + bs_hiv + bupacts + sex,
                   family = poisson(link = "log"),
                   data = risky,
                   refresh = 0)
#summary table
print(fit1512, digit = 3)
#overdispersion check
check_overdispersion(fit1512)
```

The new model with more variables is better than the first model, which lower Pearson's Chi-squared value and lower dispersion ratio, however, the dispersion ratio is still high as 30, which indicates that the overdispersion still exist in the model.

### c) 
Fit a negative binomial (overdispersed Poisson) model. What do you conclude regarding effectiveness of the intervention?

```{r}
#set the offset
risky$offset <- ifelse(risky$bupacts == 0,
                       1,
                       risky$bupacts)
#fit the model
fit1513 <- stan_glm(fupacts ~ women_alone + couples + bs_hiv + sex,
                   family = neg_binomial_2,
                   offset = log(offset),
                   data = risky,
                   refresh = 0)
#summary table
print(fit1513, digits = 3)
#check overdispersion
check_overdispersion(fit1513)
```

After adjusting the baseline level, the coefficient of women_alone shows that the group in which just the woman participated can reduce $1-e^{-0.588}=1-0.5554=0.4446$, 44.46% counts in unprotected sexual acts. 

The coefficient of couples1 shows that the group in which both members of the couple participated can reduce $1-e^{-0.483}=1-0.6169=0.3831$, 38.31% counts in unprotected sexual acts. 

The coefficient of bs_hiv shows that in the controlling group, participant with positive HIV test can reduce $1-e^{-0.37}=0.3092$, 30.92% counts in unprotected sexual acts compared with participant with negative HIV test.

The coefficient of sexwoman shows that compare with male participants, female participants has $e^{-0.162}=0.8504$, 85.04% lower counts of unprotected sexual acts.

### d) 
These data include responses from both men and women from the participating couples. Does this give you any concern with regard to our modeling assumptions? 

Yes, since both male and female are participant in this test and are documented by the variable couple and women_alone, also, male and female from same couple could have highly similar answer, which could break the independent and identification of the data distribution, cause the modeling assumptions into wrong position.


## 15.3 Binomial regression
Redo the basketball shooting example on page 270, making some changes:  

### (a) 
Instead of having each player shoot 20 times, let the number of shots per player vary, drawn from the uniform distribution between 10 and 30.  
```{r}
#set variables
set.seed(153)
N <- 100
height <- rnorm(N,72,3)
p <- 0.4 + 0.1*(height-72)/3
n <- round(runif(N,10,30))
y <- rbinom(N,n,p)
shoot <- data.frame(n = n,
                   y = y,
                   height = height)
#fit binomial model
fit1531 <- stan_glm(cbind(y, n-y) ~ height,
                    family = binomial(link = "logit"),
                    data = shoot,
                    refresh = 0)
print(fit1531, digit = 3)
```

### (b) 
Instead of having the true probability of success be linear, have the true probability be a logistic function, set so that Pr(success) = 0.3 for a player who is 5'9" and 0.4 for a 6' tall player. 

```{r}
#set data
p <- invlogit(-0.4 + 0.4*((height - 72)/3))
y <- rbinom(N,n,p)
shoot <- data.frame(n = n,
                   y = y,
                   height = height)
#fit moidel 
fit_1532 <- stan_glm(cbind(y, n-y) ~ height, 
                     family=binomial(link="logit"), 
                     data=shoot, 
                     refresh=0)
#summary table
print(fit_1532, digit = 3)
```


## 15.7 Tobit model for mixed discrete/continuous data
Experimental data from the National Supported  Work example are in the folder `Lalonde`. Use the treatment indicator and pre-treatment variables to predict post-treatment (1978) earnings using a Tobit model. Interpret the model coefficients. 

```{r}
#read table
lalonde <- read_dta("../data/ROS-Examples-master/Lalonde/NSW_dw_obs.dta")
#tobit model
fit157 <- vglm(re78 ~ treat + age + married + sample + educ_cat4 + educ + black, 
               tobit(), 
               data=lalonde)
#summary table
summary(fit157)
```

The coefficients of variables `treat, age, married, sample educ_cat4, educ` are all positive, indicates that treated participants have higher income than untreated one, married participants has higher income than single one, elder has higher income than younger, higher educated participants has higher income. The coefficient of variable `black` is -0.003165, which indicates that black ethnicity has a negative impact on income.

## 15.8 Robust linear regression using the t model
The folder `Congress` has the votes for the Democratic and Republican candidates in each U.S. congressional district in 1988, along with the parties' vote proportions in 1986 and an indicator for whether the incumbent was running for reelection in 1988. For your analysis, just use the elections that were contested by both parties in both years.  

```{r}
#read data
congress <- read.csv("../data/ROS-Examples-master/Congress/data/congress.csv")
#tidy data
congress %>% 
  transmute(vote = v88_adj,
            past_vote = v86_adj,
            inc = inc88) -> congress
```

### (a) 
Fit a linear regression using `stan_glm` with the usual normal-distribution model for the errors predicting 1988 Democratic vote share from the other variables and assess model fit.

```{r}
#fit a linear regression with the usual normal-distribution model.
fit158 <- stan_glm(vote ~ past_vote + inc,
                   data = congress,
                   refresh = 0)
print(fit158, digit = 3)
```

### (b) 
Fit the same sort of model using the `brms` package with a $t$ distribution, using the `brm` function with the student family. Again assess model fit.  

```{r}
fit1582 <- brms::brm(vote ~ past_vote + inc,
                     data = congress,
                     family = student,
                     refresh = 0)
print(fit1582, digit = 3)
```

### (c) 
Which model do you prefer? 

```{r}
#compare two models by loo.
loo158 <- loo(fit158)
loo1582 <- loo(fit1582)
loo_compare(loo158,loo1582)
```

$2\times se=2\times5.5=11$
the epld_diff is close to 2SE, which indicates the robust regression using the t model is much better.

## 15.9 Robust regression for binary data using the robit model
Use the same data as the previous example with the goal instead of predicting for each district whether it was won by the Democratic or Republican candidate.  

### (a) 
Fit a standard logistic or probit regression and assess model fit.

```{r}
#set a new dependent variable about whether Democratic candidates win the election
congress$win <- ifelse(congress$vote > 0.5,1,0)
#fit a logistic regression model
fit159 <- stan_glm(win ~ past_vote + inc,
                   data = congress,
                   family = binomial(link = "logit"),
                   refresh = 0)
#summary table
print(fit159, digit = 3)
#residual plot
plot(fit159$fitted.values,
     fit159$residuals,
     xlab = "Estimated value",
     ylab = "residuals",
     main = "Residual plot")
abline(h=0,lty=2,col="grey")
```

The residual plot shows that the model fits the data well.

### (b) 
Fit a robit regression and assess model fit.

```{r}
#fit a robit regression
fit1592 <- brms::brm(win ~ past_vote + inc,
                     data = congress,
                     family = bernoulli,
                     refresh = 0)
print(fit1592, digit = 3)
```

### (c) 
Which model do you prefer? 
```{r}
loo159 <- loo(fit159)
loo1592 <- loo(fit1592)
loo_compare(loo159, loo1592)
```

robit regression model is slightly better than the logistic regression model.

## 15.14 Model checking for count data
The folder `RiskyBehavior` contains data from a study of behavior of couples at risk for HIV; see Exercise 15.1. 

### (a) 
Fit a Poisson regression predicting number of unprotected sex acts from baseline HIV status. Perform predictive simulation to generate 1000 datasets and record the percentage of observations that are equal to 0 and the percentage that are greater than 10 (the third quartile in the observed data) for each. Compare these to the observed value in the original data.

```{r}
#fit a Poisson regression
fit1514 <- stan_glm(fupacts ~ bs_hiv,
                    family = poisson(link = "log"),
                    data = risky,
                    refresh = 0)
#predict
y_rep <- posterior_predict(fit1514)
nsims <- 1000
subset <- sample(nsims, 1000)
ppc_dens_overlay(log10(risky$fupacts+1),log10(y_rep[subset,]+1))
```

### (b) 
Repeat (a) using a negative binomial (overdispersed Poisson) regression.

```{r}
#fit a negative binomial regression model
fit15142 <- stan_glm(fupacts ~ bs_hiv,
                    family = neg_binomial_2,
                    data = risky,
                    refresh = 0)
#predict
y_rep2 <- posterior_predict(fit15142)
ppc_dens_overlay(log10(risky$fupacts+1),log10(y_rep2[subset,]+1))
```

### (c) 
Repeat (b), also including ethnicity and baseline number of unprotected sex acts as inputs.

```{r}
#fit the negative binomial regression model with three categorical and bs_hive, set baseline number of unprotected sex acts as inputs
fit15143 <- stan_glm(fupacts ~ bupacts + bs_hiv,
                     family = neg_binomial_2,
                     data = risky,
                     refresh = 0)
#predict
y_rep3 <- posterior_predict(fit15143)
ppc_dens_overlay(log10(risky$fupacts+1),log10(y_rep3[subset,]+1))
```


## 15.15 Summarizing inferences and predictions using simulation
Exercise 15.7 used a Tobit model to fit a regression with an outcome that had mixed discrete and continuous data. In this exercise you will revisit these data and build a two-step model: 
(1) logistic regression for zero earnings versus positive earnings, and 
(2) linear regression for level of earnings given earnings are positive. 
Compare predictions that result from each of these models with each other. 

```{r}
#convert re78 into a binary variable
lalonde$re78bin <- ifelse(lalonde$re78 == 0, 0, 1)
#(1) logistic regression for zero earnings versus positive earnings
fit15151 <- stan_glm(re78bin ~ treat + 
                       age + 
                       married + 
                       sample + 
                       educ_cat4 + 
                       educ + 
                       black, 
                     family = binomial(link = "logit"), 
                     data=lalonde, 
                     refresh=0)
#(2) linear regression for level of earnings given earnings are positive.
fit15152 <- stan_glm(re78 ~ treat + 
                       age + 
                       married + 
                       sample + 
                       educ_cat4 + 
                       educ + 
                       black, 
                     data=lalonde, 
                     subset = re78>0, 
                     refresh=0)
#display the two models and compare them.
summary(fit15151, digits = 3)
summary(fit15152, digits = 3)
```

In the first model, 

  - variables `married, sample, educat4` indicate that increase in these variables could let to a positive increase in the likelihood of earnings.
  
  - variables `treat, age, edu, black` indicate that increase in these variables could let to a negative decrease in the likelihood of earnings.
  
In the second model,

  - variables with positive coefficients indicates that increase in these variables could let to a direct positive impact on earnings and verse visa.
  
  - variables with negative coefficients indicates that increase in these variables could let to a direct negative impact on earnings and verse visa.
